# app.py â€” ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%) ë¶„ì„ (ì˜¤ë¥˜ ìˆ˜ì •íŒ)
# - GitHub raw XLSX/CSV ë¡œë”©(blob â†’ raw ìë™ ë³€í™˜)
# - ì›” ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„ ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%)  =  (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê³µê¸‰ëŸ‰ Ã· ì›” ì´ê³µê¸‰ëŸ‰)Ã—100
# - ì—°ë„ ì„ íƒ(ì‚¬ì´ë“œë°”), ìš”ì¼/ê³µíœ´ì¼ ë©€í‹°ì„ íƒ
# - íˆíŠ¸ë§µ(í¬ê²Œ), 100% ëˆ„ì  ë§‰ëŒ€(ì—°ê°„ êµ¬ì¡° ë³€í™”), ìš”ì¼ë³„ ì¶”ì„¸ì„ (ë¹ˆ ë‹¬/ë¯¸ë˜ì—°ë„ ì œê±°)
# - í•˜ë‹¨ ìë™ ìš”ì•½/ê²°ë¡ 

import re
from urllib.parse import urlparse
import numpy as np
import pandas as pd
import requests
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘ ë¶„ì„", layout="wide")

st.title("ğŸ“Š ì›”ë³„ ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„ ìš”ì¼Â·ê³µíœ´ì¼ **ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%)**")
st.caption("â€» â€˜ê³µê¸‰ëŸ‰ ë¹„ì¤‘â€™ì€ ì›” ì´ê³µê¸‰ëŸ‰ì—ì„œ ì„ íƒëœ ìš”ì¼/ê³µíœ´ì¼ì´ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘(%)ì„ ì˜ë¯¸")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    raw_url = st.text_input(
        "GitHub raw íŒŒì¼ URL (xlsx/csv)",
        value="https://raw.githubusercontent.com/Han11112222/Industrial-effective-days/main/effective_days_calendar.xlsx",
        help="íŒŒì¼ í˜ì´ì§€ì˜ Raw ì£¼ì†Œ. blob ì£¼ì†Œë¥¼ ë„£ì–´ë„ ìë™ ë³€í™˜ë¨."
    )
    split_holiday = st.radio(
        "ê³µíœ´ì¼ì„ ë³„ë„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¦¬(í•©ê³„ 100%)",
        options=["ì˜ˆ(ê¶Œì¥)","ì•„ë‹ˆì˜¤(í•´ë‹¹ ìš”ì¼ì— í¬í•¨)"], index=0, horizontal=True
    ) == "ì˜ˆ(ê¶Œì¥)"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_github_url(url: str) -> str:
    u = url.strip()
    if "raw.githubusercontent.com" in u:
        return u.split("?")[0]
    if "github.com" in u and "/blob/" in u:
        owner_repo, path = u.split("github.com/")[1].split("/blob/")
        return f"https://raw.githubusercontent.com/{owner_repo}/{path}".split("?")[0]
    return u

@st.cache_data(show_spinner=False)
def load_df(url: str) -> pd.DataFrame:
    url = normalize_github_url(url)
    parsed = urlparse(url)
    if "raw.githubusercontent.com" not in parsed.netloc:
        raise ValueError("GitHub raw URLì´ ì•„ë‹˜")

    h = requests.head(url, timeout=10)
    if h.status_code == 404:
        raise FileNotFoundError("HTTP 404 â€” ë¸Œëœì¹˜/ê²½ë¡œ/íŒŒì¼ëª… í™•ì¸")
    h.raise_for_status()

    if url.lower().endswith((".xlsx",".xls")):
        import openpyxl  # noqa: F401
        df = pd.read_excel(url, engine="openpyxl")
    elif url.lower().endswith(".csv"):
        try: df = pd.read_csv(url, encoding="cp949")
        except: df = pd.read_csv(url, encoding="utf-8")
    else:
        raise ValueError("ì§€ì› í™•ì¥ì: .xlsx, .xls, .csv")
    return df

def to_float(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int,float,np.number)): return float(x)
    return float(str(x).replace(",",""))

def parse_date8(s):
    s = str(s).strip()
    if re.fullmatch(r"\d{8}", s):
        return pd.to_datetime(s, format="%Y%m%d")
    return pd.to_datetime(s, errors="coerce")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Load & normalize
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    raw = load_df(raw_url)
    st.success("ë°ì´í„° ë¡œë”© ì™„ë£Œ")
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

need = ["ë‚ ì§œ","ì—°","ì›”","ìš”ì¼","ê³µíœ´ì¼ì—¬ë¶€","ê³µê¸‰ëŸ‰(MJ)"]
missing = [c for c in need if c not in raw.columns]
if missing:
    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    st.stop()

df = raw.copy()
df["ë‚ ì§œ_dt"] = df["ë‚ ì§œ"].apply(parse_date8)
df["ì—°"] = pd.to_numeric(df["ì—°"], errors="coerce").astype("Int64")
df["ì›”"] = pd.to_numeric(df["ì›”"], errors="coerce").astype("Int64")
df["ìš”ì¼"] = df["ìš”ì¼"].astype(str).str.strip()
df["ê³µíœ´ì¼ì—¬ë¶€"] = df["ê³µíœ´ì¼ì—¬ë¶€"].astype(str).str.upper().isin(["TRUE","T","1","Y","YES"])
df["ê³µê¸‰ëŸ‰(MJ)"] = df["ê³µê¸‰ëŸ‰(MJ)"].apply(to_float)

def cat_fn(r):
    if split_holiday and r["ê³µíœ´ì¼ì—¬ë¶€"]:
        return "ê³µíœ´ì¼"
    return r["ìš”ì¼"]
df["ì¹´í…Œê³ ë¦¬"] = df.apply(cat_fn, axis=1)

# ì›” ì´ê³µê¸‰ëŸ‰, ì¹´í…Œê³ ë¦¬ ê³µê¸‰ëŸ‰
m_total = df.groupby(["ì—°","ì›”"], dropna=False)["ê³µê¸‰ëŸ‰(MJ)"].sum().rename("ì›”ì´ê³µê¸‰ëŸ‰")
m_cat = df.groupby(["ì—°","ì›”","ì¹´í…Œê³ ë¦¬"], dropna=False)["ê³µê¸‰ëŸ‰(MJ)"].sum().rename("ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰").reset_index()
m = m_cat.merge(m_total, on=["ì—°","ì›”"], how="left")
# **ë¹ˆ ë‹¬/ë¯¸ë˜ì—°ë„ ì œê±°**: ì›”ì´ê³µê¸‰ëŸ‰>0ë§Œ ìœ ì§€
m = m[m["ì›”ì´ê³µê¸‰ëŸ‰"] > 0].copy()
m["ë¹„ì¤‘(%)"] = m["ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰"] / m["ì›”ì´ê³µê¸‰ëŸ‰"] * 100

# ì‚¬ì´ë“œë°” ì—°ë„ ì„ íƒ
valid_years = [int(y) for y in sorted(m["ì—°"].dropna().unique())]
with st.sidebar:
    sel_years = st.multiselect("ì—°ë„ ì„ íƒ", options=valid_years, default=valid_years)

weekday_order = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"] + (["ê³µíœ´ì¼"] if "ê³µíœ´ì¼" in m["ì¹´í…Œê³ ë¦¬"].unique() else [])
cats_all = [c for c in weekday_order if c in m["ì¹´í…Œê³ ë¦¬"].unique()]
st.caption("**ìš©ì–´ í™•ì¸** â€” â€˜ë¹„ì¤‘â€™ì€ *ì›” ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„* **ì„ íƒëœ ìš”ì¼/ê³µíœ´ì¼ì˜ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%)**")

view = m[m["ì—°"].isin(sel_years)].copy()

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) íˆíŠ¸ë§µ (í¬ê²Œ) â€” íŠ¹ì • ì¹´í…Œê³ ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
default_cat = "ê¸ˆ" if "ê¸ˆ" in cats_all else cats_all[0]
target_cat = st.selectbox("íˆíŠ¸ë§µì— ë³¼ ì¹´í…Œê³ ë¦¬", options=cats_all, index=cats_all.index(default_cat))

hm = view[view["ì¹´í…Œê³ ë¦¬"] == target_cat]
pivot = hm.pivot_table(index="ì—°", columns="ì›”", values="ë¹„ì¤‘(%)", aggfunc="mean").reindex(
    index=sorted(hm["ì—°"].unique()), columns=range(1,13)
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì—°ë„ë³„ êµ¬ì¡° ë³€í™” â€” 100% ëˆ„ì  ë§‰ëŒ€ (ì „ì²´ ì¹´í…Œê³ ë¦¬)  â† êµì²´ë³¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§± ì—°ë„ë³„ êµ¬ì¡° ë³€í™” â€” ëª¨ë“  ìš”ì¼/ê³µíœ´ì¼ **ì—°ê°„ í‰ê·  ë¹„ì¤‘(%)** (100% ê¸°ì¤€)")

# 1) ì—°Â·ì¹´í…Œê³ ë¦¬ í‰ê·  ë¹„ì¤‘ ì§‘ê³„
year_cat = view.groupby(["ì—°","ì¹´í…Œê³ ë¦¬"], as_index=False)["ë¹„ì¤‘(%)"].mean()

# 2) ì—°ë„ë³„ë¡œ í•©ì´ 100ì´ ë˜ë„ë¡ ì •ê·œí™” (barnorm ì‚¬ìš© ì•ˆ í•¨)
norm = (
    year_cat
    .groupby("ì—°", as_index=False)["ë¹„ì¤‘(%)"].sum()
    .rename(columns={"ë¹„ì¤‘(%)":"í•©ê³„"})
)
year_cat = year_cat.merge(norm, on="ì—°", how="left")
year_cat["ì—°ê°„ ì •ê·œí™”(%)"] = np.where(year_cat["í•©ê³„"]>0,
                                  year_cat["ë¹„ì¤‘(%)"] / year_cat["í•©ê³„"] * 100, 0.0)

# 3) ìš”ì¼ ìˆœì„œ ì •ë ¬(ìˆì„ ë•Œë§Œ)
weekday_order = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼","ê³µíœ´ì¼"]
cats_in = [c for c in weekday_order if c in year_cat["ì¹´í…Œê³ ë¦¬"].unique()]
year_cat["ì¹´í…Œê³ ë¦¬"] = pd.Categorical(year_cat["ì¹´í…Œê³ ë¦¬"], categories=cats_in, ordered=True)
year_cat = year_cat.sort_values(["ì—°","ì¹´í…Œê³ ë¦¬"])

# 4) 100% ëˆ„ì  ë§‰ëŒ€ (stack)
fig_stack = px.bar(
    year_cat, x="ì—°", y="ì—°ê°„ ì •ê·œí™”(%)", color="ì¹´í…Œê³ ë¦¬",
    labels={"ì—°":"ì—°ë„","ì—°ê°„ ì •ê·œí™”(%)":"ì—° í‰ê·  ë¹„ì¤‘(%)"},
)
fig_stack.update_layout(
    barmode="stack",  # ëˆ„ì 
    yaxis=dict(range=[0, 100]),
    margin=dict(l=30,r=20,t=10,b=40),
    xaxis=dict(type="category"),
    font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic")
)
st.plotly_chart(fig_stack, use_container_width=True)

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì—°ë„ë³„ êµ¬ì¡° ë³€í™” â€” 100% ëˆ„ì  ë§‰ëŒ€ (ì „ì²´ ì¹´í…Œê³ ë¦¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§± ì—°ë„ë³„ êµ¬ì¡° ë³€í™” â€” ëª¨ë“  ìš”ì¼/ê³µíœ´ì¼ **ì—°ê°„ í‰ê·  ë¹„ì¤‘(%)** (100% ê¸°ì¤€)")
year_cat = view.groupby(["ì—°","ì¹´í…Œê³ ë¦¬"], as_index=False)["ë¹„ì¤‘(%)"].mean()
fig_stack = px.bar(
    year_cat, x="ì—°", y="ë¹„ì¤‘(%)", color="ì¹´í…Œê³ ë¦¬", barnorm="percent",
    labels={"ì—°":"ì—°ë„","ë¹„ì¤‘(%)":"ì—° í‰ê·  ë¹„ì¤‘(%)"},
)
fig_stack.update_layout(margin=dict(l=30,r=20,t=10,b=40), xaxis=dict(type="category"),
                        font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic"))
st.plotly_chart(fig_stack, use_container_width=True)

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ìš”ì¼/ê³µíœ´ì¼ë³„ ì¶”ì„¸ì„  (ë¹ˆ ë‹¬ ì œê±°)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ ìš”ì¼/ê³µíœ´ì¼ë³„ ë™ì  ì¶”ì„¸ì„  â€” ì›”ë³„ ë¹„ì¤‘(%)")
sel_cats = st.multiselect("ë¹„êµí•  ì¹´í…Œê³ ë¦¬ ì„ íƒ", options=cats_all,
                          default=["ê¸ˆ"] if "ê¸ˆ" in cats_all else cats_all[:2])

ts = view[view["ì¹´í…Œê³ ë¦¬"].isin(sel_cats)].copy()
ts["t"] = ts["ì—°"].astype(int)*12 + ts["ì›”"].astype(int)
ts = ts.sort_values(["ì¹´í…Œê³ ë¦¬","ì—°","ì›”"])

fig_ts = go.Figure()
summary_rows = []
for c in sel_cats:
    s = ts[ts["ì¹´í…Œê³ ë¦¬"]==c].dropna(subset=["ë¹„ì¤‘(%)"])
    s = s[(s["ì›”ì´ê³µê¸‰ëŸ‰"]>0)]
    s["ì—°ì›”"] = s["ì—°"].astype(int).astype(str) + "-" + s["ì›”"].astype(int).astype(str).str.zfill(2)
    fig_ts.add_trace(go.Scatter(x=s["ì—°ì›”"], y=s["ë¹„ì¤‘(%)"], mode="lines+markers", name=f"{c}"))
    if len(s) >= 3:
        a, b = np.polyfit(s["t"], s["ë¹„ì¤‘(%)"], 1)  # y=a*t+b
        trend = a*s["t"] + b
        fig_ts.add_trace(go.Scatter(x=s["ì—°ì›”"], y=trend, mode="lines",
                                    name=f"{c} ì¶”ì„¸", line=dict(dash="dash")))
        slope_year = a*12  # ì›” ë‹¨ìœ„ ê³„ìˆ˜ â†’ ì—° ë‹¨ìœ„ p.p./ë…„
        s["ì—°_int"] = s["ì—°"].astype(int)
        early = s[s["ì—°_int"] <= s["ì—°_int"].min()+2]["ë¹„ì¤‘(%)"].mean()
        late  = s[s["ì—°_int"] >= s["ì—°_int"].max()-2]["ë¹„ì¤‘(%)"].mean()
        summary_rows.append({"ì¹´í…Œê³ ë¦¬": c,
                             "ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)": float(slope_year),
                             "ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)": float(late - early)})

fig_ts.update_layout(xaxis_title="ì—°-ì›”", yaxis_title="ë¹„ì¤‘(%)",
                     font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic"),
                     legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
st.plotly_chart(fig_ts, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ìƒì„¸/ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“„ ìƒì„¸ í…Œì´ë¸”(ì—°Â·ì›”Â·ì¹´í…Œê³ ë¦¬)")
table = view.sort_values(["ì—°","ì›”","ì¹´í…Œê³ ë¦¬"]).copy()
st.dataframe(
    table[["ì—°","ì›”","ì¹´í…Œê³ ë¦¬","ì›”ì´ê³µê¸‰ëŸ‰","ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰","ë¹„ì¤‘(%)"]]
        .style.format({"ì›”ì´ê³µê¸‰ëŸ‰":"{:,.0f}","ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰":"{:,.0f}","ë¹„ì¤‘(%)":"{:.2f}"}),
    use_container_width=True
)
st.download_button("CSV ë‹¤ìš´ë¡œë“œ(í˜„ì¬ ë³´ê¸°)", data=table.to_csv(index=False, encoding="utf-8-sig"),
                   file_name="weekday_holiday_share_monthly.csv", mime="text/csv")

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ìë™ ìš”ì•½/ê²°ë¡   (â¬…ï¸ ì˜¤ë¥˜ë‚¬ë˜ ë¶€ë¶„ ê¹”ë”íˆ êµì²´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§­ ìš”ì•½ ë° ê²°ë¡ ")
txts = []

# (a) ê¸ˆìš”ì¼ ì¤‘ì‹¬ ìš”ì•½
if "ê¸ˆ" in m["ì¹´í…Œê³ ë¦¬"].unique():
    s = view[view["ì¹´í…Œê³ ë¦¬"]=="ê¸ˆ"]
    if not s.empty:
        yavg = s.groupby("ì—°")["ë¹„ì¤‘(%)"].mean()
        if len(yavg)>=2:
            first3 = yavg.sort_index().iloc[:min(3,len(yavg))].mean()
            last3  = yavg.sort_index().iloc[-min(3,len(yavg)) :].mean()
            diff = last3 - first3
            direction = "ê°ì†Œ" if diff < 0 else "ì¦ê°€"
            txts.append(f"- **ê¸ˆìš”ì¼ ì—°í‰ê·  ë¹„ì¤‘**: ì´ˆê¸° 3ë…„ ëŒ€ë¹„ ìµœê·¼ 3ë…„ {abs(diff):.2f}p.p. **{direction}**")

# (b) ì „ì²´ êµ¬ì¡° ë³€í™”(ì—° í‰ê· , ìµœê·¼ vs ì´ˆê¸°)
year_cat_all = view.groupby(["ì—°","ì¹´í…Œê³ ë¦¬"], as_index=False)["ë¹„ì¤‘(%)"].mean()
weekday_order2 = [c for c in weekday_order if c in year_cat_all["ì¹´í…Œê³ ë¦¬"].unique()]
summary_change = []
for c in weekday_order2:
    s = year_cat_all[year_cat_all["ì¹´í…Œê³ ë¦¬"]==c].sort_values("ì—°")
    if len(s)>=2:
        early = s["ë¹„ì¤‘(%)"].iloc[:min(3,len(s))].mean()
        late  = s["ë¹„ì¤‘(%)"].iloc[-min(3,len(s)) :].mean()
        summary_change.append((c, late-early))
if summary_change:
    summary_change.sort(key=lambda x: x[1], reverse=True)
    inc = [f"{c} (+{d:.2f}p)" for c,d in summary_change if d>0]
    dec = [f"{c} ({d:.2f}p)" for c,d in summary_change if d<0]
    if inc: txts.append("- **ë¹„ì¤‘ì´ ëŠ˜ì–´ë‚œ ìš”ì¼/ê³µíœ´ì¼**: " + ", ".join(inc))
    if dec: txts.append("- **ë¹„ì¤‘ì´ ì¤„ì–´ë“  ìš”ì¼/ê³µíœ´ì¼**: " + ", ".join(dec))

# (c) ì¶”ì„¸ì„  ìš”ì•½(ì„ íƒ ì¹´í…Œê³ ë¦¬)
if summary_rows:
    sr = pd.DataFrame(summary_rows).sort_values("ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)", ascending=False)
    inc_line = f"- **ì¶”ì„¸ì„  ì¦ê°€ 1ìœ„**: {sr.iloc[0]['ì¹´í…Œê³ ë¦¬']} (ê¸°ìš¸ê¸° {sr.iloc[0]['ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)']:.2f}p/ë…„, ìµœê·¼-ì´ˆê¸° {sr.iloc[0]['ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)']:.2f}p)"
    dec_line = f"- **ì¶”ì„¸ì„  ê°ì†Œ 1ìœ„**: {sr.iloc[-1]['ì¹´í…Œê³ ë¦¬']} (ê¸°ìš¸ê¸° {sr.iloc[-1]['ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)']:.2f}p/ë…„, ìµœê·¼-ì´ˆê¸° {sr.iloc[-1]['ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)']:.2f}p)"
    txts.extend([inc_line, dec_line])

if not txts:
    txts = ["- ì„ íƒëœ êµ¬ê°„ì—ì„œ ëšœë ·í•œ êµ¬ì¡° ë³€í™” ì‹ í˜¸ê°€ ì•½í•¨(ì—°ë„/ìš”ì¼ ì„ íƒì„ ë°”ê¿” í™•ì¸)."]

st.markdown("\n".join(txts))
