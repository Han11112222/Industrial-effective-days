# app.py â€” ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%) ë¶„ì„ (ë§‰ëŒ€ê·¸ëž˜í”„+ì¶”ì„¸ì„  ê°œì„ íŒ)
# - GitHub raw XLSX/CSV ë¡œë”©(blob â†’ raw ìžë™ ë³€í™˜)
# - ì›” ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„ ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%) ê³„ì‚°
# - ì—°ë„ ì„ íƒ(ì‚¬ì´ë“œë°”), ì¹´í…Œê³ ë¦¬ ë©€í‹°ì„ íƒ
# - ì‹œê°í™”:
#   (A) ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ì—°ë„Ã—ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ ë§‰ëŒ€ê·¸ëž˜í”„
#   (B) ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì„¸ì„ (ì—° ë‹¨ìœ„)
#   (C) ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ ížˆíŠ¸ë§µ(ì„ íƒí˜•, í¬ê²Œ)
# - ë¹ˆ ë‹¬/ë¯¸ëž˜ì—°ë„(ì›”ì´ê³µê¸‰ëŸ‰=0) ì œê±°

import re
from urllib.parse import urlparse
import numpy as np
import pandas as pd
import requests
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ìš”ì¼/ê³µíœ´ì¼ ê³µê¸‰ëŸ‰ ë¹„ì¤‘ ë¶„ì„", layout="wide")
st.title("ðŸ“Š ì›”ë³„ ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„ ìš”ì¼Â·ê³µíœ´ì¼ **ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%)**")
st.caption("â€» â€˜ê³µê¸‰ëŸ‰ ë¹„ì¤‘â€™ = (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê³µê¸‰ëŸ‰ Ã· ì›” ì´ê³µê¸‰ëŸ‰) Ã— 100")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    raw_url = st.text_input(
        "GitHub raw íŒŒì¼ URL (xlsx/csv)",
        value="https://raw.githubusercontent.com/Han11112222/Industrial-effective-days/main/effective_days_calendar.xlsx",
        help="íŒŒì¼ íŽ˜ì´ì§€ì˜ Raw ì£¼ì†Œ. blob ì£¼ì†Œì—¬ë„ ìžë™ ë³€í™˜ë¨."
    )
    split_holiday = st.radio(
        "ê³µíœ´ì¼ì„ ë³„ë„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¦¬(í•©ê³„ 100%)",
        options=["ì˜ˆ(ê¶Œìž¥)","ì•„ë‹ˆì˜¤(í•´ë‹¹ ìš”ì¼ì— í¬í•¨)"], index=0, horizontal=True
    ) == "ì˜ˆ(ê¶Œìž¥)"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_github_url(url: str) -> str:
    u = url.strip()
    if "raw.githubusercontent.com" in u:
        return u.split("?")[0]
    if "github.com" in u and "/blob/" in u:
        owner_repo, path = u.split("github.com/")[1].split("/blob/")
        return f"https://raw.githubusercontent.com/{owner_repo}/{path}".split("?")[0]
    return u

@st.cache_data(show_spinner=False)
def load_df(url: str) -> pd.DataFrame:
    url = normalize_github_url(url)
    parsed = urlparse(url)
    if "raw.githubusercontent.com" not in parsed.netloc:
        raise ValueError("GitHub raw URLì´ ì•„ë‹˜")

    h = requests.head(url, timeout=10)
    if h.status_code == 404:
        raise FileNotFoundError("HTTP 404 â€” ë¸Œëžœì¹˜/ê²½ë¡œ/íŒŒì¼ëª… í™•ì¸")
    h.raise_for_status()

    if url.lower().endswith((".xlsx",".xls")):
        import openpyxl  # noqa: F401
        df = pd.read_excel(url, engine="openpyxl")
    elif url.lower().endswith(".csv"):
        try: df = pd.read_csv(url, encoding="cp949")
        except: df = pd.read_csv(url, encoding="utf-8")
    else:
        raise ValueError("ì§€ì› í™•ìž¥ìž: .xlsx, .xls, .csv")
    return df

def to_float(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int,float,np.number)): return float(x)
    return float(str(x).replace(",",""))

def parse_date8(s):
    s = str(s).strip()
    if re.fullmatch(r"\d{8}", s):
        return pd.to_datetime(s, format="%Y%m%d")
    return pd.to_datetime(s, errors="coerce")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Load & normalize
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    raw = load_df(raw_url)
    st.success("ë°ì´í„° ë¡œë”© ì™„ë£Œ")
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

need = ["ë‚ ì§œ","ì—°","ì›”","ìš”ì¼","ê³µíœ´ì¼ì—¬ë¶€","ê³µê¸‰ëŸ‰(MJ)"]
missing = [c for c in need if c not in raw.columns]
if missing:
    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    st.stop()

df = raw.copy()
df["ë‚ ì§œ_dt"] = df["ë‚ ì§œ"].apply(parse_date8)
df["ì—°"] = pd.to_numeric(df["ì—°"], errors="coerce").astype("Int64")
df["ì›”"] = pd.to_numeric(df["ì›”"], errors="coerce").astype("Int64")
df["ìš”ì¼"] = df["ìš”ì¼"].astype(str).str.strip()
df["ê³µíœ´ì¼ì—¬ë¶€"] = df["ê³µíœ´ì¼ì—¬ë¶€"].astype(str).str.upper().isin(["TRUE","T","1","Y","YES"])
df["ê³µê¸‰ëŸ‰(MJ)"] = df["ê³µê¸‰ëŸ‰(MJ)"].apply(to_float)

def cat_fn(r):
    if split_holiday and r["ê³µíœ´ì¼ì—¬ë¶€"]:
        return "ê³µíœ´ì¼"
    return r["ìš”ì¼"]
df["ì¹´í…Œê³ ë¦¬"] = df.apply(cat_fn, axis=1)

# ì›” ì´ê³µê¸‰ëŸ‰, ì¹´í…Œê³ ë¦¬ ê³µê¸‰ëŸ‰
m_total = df.groupby(["ì—°","ì›”"], dropna=False)["ê³µê¸‰ëŸ‰(MJ)"].sum().rename("ì›”ì´ê³µê¸‰ëŸ‰")
m_cat = df.groupby(["ì—°","ì›”","ì¹´í…Œê³ ë¦¬"], dropna=False)["ê³µê¸‰ëŸ‰(MJ)"].sum().rename("ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰").reset_index()
m = m_cat.merge(m_total, on=["ì—°","ì›”"], how="left")

# **ë¹ˆ ë‹¬/ë¯¸ëž˜ì—°ë„ ì œê±°**: ì›”ì´ê³µê¸‰ëŸ‰>0ë§Œ ìœ ì§€
m = m[m["ì›”ì´ê³µê¸‰ëŸ‰"] > 0].copy()
m["ë¹„ì¤‘(%)"] = m["ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰"] / m["ì›”ì´ê³µê¸‰ëŸ‰"] * 100

# ì—°ë„/ì¹´í…Œê³ ë¦¬ ëª©ë¡
weekday_order = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼","ê³µíœ´ì¼"]
cats_all = [c for c in weekday_order if c in m["ì¹´í…Œê³ ë¦¬"].unique()]
valid_years = [int(y) for y in sorted(m["ì—°"].dropna().unique())]

with st.sidebar:
    sel_years = st.multiselect("ì—°ë„ ì„ íƒ", options=valid_years, default=valid_years)

st.caption("**ìš©ì–´ í™•ì¸** â€” â€˜ë¹„ì¤‘â€™ì€ *ì›” ì´ê³µê¸‰ëŸ‰ ëŒ€ë¹„* **ì„ íƒëœ ìš”ì¼/ê³µíœ´ì¼ì˜ ê³µê¸‰ëŸ‰ ë¹„ì¤‘(%)**")
view = m[m["ì—°"].isin(sel_years)].copy()

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (A) ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ê·¸ë£¹ ë§‰ëŒ€ê·¸ëž˜í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ðŸ§± ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ì—°ë„Ã—ì¹´í…Œê³ ë¦¬ **ê·¸ë£¹ ë§‰ëŒ€ê·¸ëž˜í”„**")
year_cat = view.groupby(["ì—°","ì¹´í…Œê³ ë¦¬"], as_index=False)["ë¹„ì¤‘(%)"].mean()
# ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì •ë ¬
year_cat["ì¹´í…Œê³ ë¦¬"] = pd.Categorical(year_cat["ì¹´í…Œê³ ë¦¬"], categories=cats_all, ordered=True)
year_cat = year_cat.sort_values(["ì—°","ì¹´í…Œê³ ë¦¬"])

fig_group = px.bar(
    year_cat, x="ì—°", y="ë¹„ì¤‘(%)", color="ì¹´í…Œê³ ë¦¬",
    barmode="group", labels={"ì—°":"ì—°ë„","ë¹„ì¤‘(%)":"ì—°ê°„ í‰ê·  ë¹„ì¤‘(%)"},
)
fig_group.update_layout(margin=dict(l=30,r=20,t=10,b=40), xaxis=dict(type="category"),
                        font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic"))
st.plotly_chart(fig_group, use_container_width=True)

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (B) ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì„¸ì„ 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ðŸ“ˆ ì—°ê°„ í‰ê·  ë¹„ì¤‘(%) â€” ì¹´í…Œê³ ë¦¬ë³„ **ì¶”ì„¸ì„ **")
trend_df = year_cat.copy().sort_values(["ì¹´í…Œê³ ë¦¬","ì—°"])
fig_tr = go.Figure()
summary_rows = []
for c in cats_all:
    s = trend_df[trend_df["ì¹´í…Œê³ ë¦¬"]==c].dropna(subset=["ë¹„ì¤‘(%)"])
    if s.empty: continue
    fig_tr.add_trace(go.Scatter(x=s["ì—°"].astype(str), y=s["ë¹„ì¤‘(%)"], mode="lines+markers", name=c))
    if len(s) >= 3:
        # ì—° ë‹¨ìœ„ íšŒê·€(ì—° ìžì²´ë¥¼ xë¡œ ì‚¬ìš©)
        x = s["ì—°"].astype(int).to_numpy()
        y = s["ë¹„ì¤‘(%)"].to_numpy()
        a, b = np.polyfit(x, y, 1)            # y = a*ì—° + b
        yhat = a*x + b
        fig_tr.add_trace(go.Scatter(x=s["ì—°"].astype(str), y=yhat, mode="lines",
                                    name=f"{c} ì¶”ì„¸", line=dict(dash="dash")))
        # ìš”ì•½ì¹˜(ì—°ê°„ ê¸°ìš¸ê¸°, ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„)
        early = s.head(min(3, len(s)))["ë¹„ì¤‘(%)"].mean()
        late  = s.tail(min(3, len(s)))["ë¹„ì¤‘(%)"].mean()
        summary_rows.append({"ì¹´í…Œê³ ë¦¬": c,
                             "ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)": float(a),
                             "ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)": float(late - early)})

fig_tr.update_layout(xaxis_title="ì—°ë„", yaxis_title="ì—°ê°„ í‰ê·  ë¹„ì¤‘(%)",
                     legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                     font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic"))
st.plotly_chart(fig_tr, use_container_width=True)

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (C) ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ ížˆíŠ¸ë§µ(ì„ íƒí˜•, í¬ê²Œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ðŸ§Š ì›”ë³„ ížˆíŠ¸ë§µ â€” ì¹´í…Œê³ ë¦¬ ì„ íƒ")
default_cat = "ê¸ˆ" if "ê¸ˆ" in cats_all else cats_all[0]
target_cat = st.selectbox("ížˆíŠ¸ë§µì— ë³¼ ì¹´í…Œê³ ë¦¬", options=cats_all, index=cats_all.index(default_cat))

hm = view[view["ì¹´í…Œê³ ë¦¬"] == target_cat]
if hm.empty:
    st.info("ì„ íƒëœ ì—°ë„/ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    pivot = hm.pivot_table(index="ì—°", columns="ì›”", values="ë¹„ì¤‘(%)", aggfunc="mean")
    pivot = pivot.reindex(index=sorted(pivot.index), columns=range(1,13))
    heat_height = max(480, 42 * max(1, len(pivot.index)))
    fig_hm = px.imshow(
        pivot.values,
        x=list(range(1,13)), y=[int(i) for i in pivot.index],
        color_continuous_scale="Viridis", origin="upper",
        labels=dict(color="ë¹„ì¤‘(%)", x="ì›”", y="ì—°"), height=heat_height
    )
    # ì…€ ë¼ë²¨
    text_vals = np.where(np.isnan(pivot.values), "", np.vectorize(lambda v: f"{v:.1f}")(pivot.values))
    fig_hm.update_traces(text=text_vals, texttemplate="%{text}", textfont=dict(size=10))
    fig_hm.update_layout(margin=dict(l=50,r=20,t=10,b=40),
                         font=dict(family="Noto Sans KR, Nanum Gothic, Malgun Gothic"))
    st.plotly_chart(fig_hm, use_container_width=True)

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒì„¸ + ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ðŸ“„ ìƒì„¸ í…Œì´ë¸”(ì—°Â·ì›”Â·ì¹´í…Œê³ ë¦¬)")
table = view.sort_values(["ì—°","ì›”","ì¹´í…Œê³ ë¦¬"]).copy()
st.dataframe(
    table[["ì—°","ì›”","ì¹´í…Œê³ ë¦¬","ì›”ì´ê³µê¸‰ëŸ‰","ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰","ë¹„ì¤‘(%)"]]
        .style.format({"ì›”ì´ê³µê¸‰ëŸ‰":"{:,.0f}","ì¹´í…Œê³ ë¦¬ê³µê¸‰ëŸ‰":"{:,.0f}","ë¹„ì¤‘(%)":"{:.2f}"}),
    use_container_width=True
)
st.download_button("CSV ë‹¤ìš´ë¡œë“œ(í˜„ìž¬ ë³´ê¸°)", data=table.to_csv(index=False, encoding="utf-8-sig"),
                   file_name="weekday_holiday_share_monthly.csv", mime="text/csv")

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìžë™ ìš”ì•½/ê²°ë¡ 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ðŸ§­ ìš”ì•½ ë° ê²°ë¡ ")
msgs = []
# ê¸ˆìš”ì¼ ìš”ì•½
if "ê¸ˆ" in year_cat["ì¹´í…Œê³ ë¦¬"].unique():
    s = year_cat[year_cat["ì¹´í…Œê³ ë¦¬"]=="ê¸ˆ"].sort_values("ì—°")
    if len(s)>=2:
        early = s.head(min(3,len(s)))["ë¹„ì¤‘(%)"].mean()
        late  = s.tail(min(3,len(s)))["ë¹„ì¤‘(%)"].mean()
        diff  = late - early
        msgs.append(f"- **ê¸ˆìš”ì¼ ì—°ê°„ í‰ê·  ë¹„ì¤‘**: ì´ˆê¸° 3ë…„ ëŒ€ë¹„ ìµœê·¼ 3ë…„ {diff:+.2f}p ë³€í™”")

# ì „ì²´ ì¦ê°€/ê°ì†Œ ìš”ì¼
chg = []
for c in cats_all:
    s = year_cat[year_cat["ì¹´í…Œê³ ë¦¬"]==c].sort_values("ì—°")
    if len(s)>=2:
        early = s.head(min(3,len(s)))["ë¹„ì¤‘(%)"].mean()
        late  = s.tail(min(3,len(s)))["ë¹„ì¤‘(%)"].mean()
        chg.append((c, late-early))
if chg:
    chg.sort(key=lambda x: x[1], reverse=True)
    inc = [f"{c} (+{d:.2f}p)" for c,d in chg if d>0]
    dec = [f"{c} ({d:.2f}p)" for c,d in chg if d<0]
    if inc: msgs.append("- **ë¹„ì¤‘ì´ ëŠ˜ì–´ë‚œ ìª½**: " + ", ".join(inc))
    if dec: msgs.append("- **ë¹„ì¤‘ì´ ì¤„ì–´ë“  ìª½**: " + ", ".join(dec))

# ì¶”ì„¸ì„  ìš”ì•½
if summary_rows:
    sr = pd.DataFrame(summary_rows).sort_values("ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)", ascending=False)
    msgs.append(f"- **ì¶”ì„¸ ì¦ê°€ 1ìœ„**: {sr.iloc[0]['ì¹´í…Œê³ ë¦¬']} ({sr.iloc[0]['ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)']:+.2f}p/ë…„, ìµœê·¼-ì´ˆê¸° {sr.iloc[0]['ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)']:+.2f}p)")
    msgs.append(f"- **ì¶”ì„¸ ê°ì†Œ 1ìœ„**: {sr.iloc[-1]['ì¹´í…Œê³ ë¦¬']} ({sr.iloc[-1]['ì—°ê°„ ê¸°ìš¸ê¸°(pp/ë…„)']:+.2f}p/ë…„, ìµœê·¼-ì´ˆê¸° {sr.iloc[-1]['ì´ˆê¸°3ë…„â†’ìµœê·¼3ë…„ ë³€í™”(pp)']:+.2f}p)")

if not msgs:
    msgs = ["- ì„ íƒ êµ¬ê°„ì—ì„œ êµ¬ì¡° ë³€í™”ê°€ ëšœë ·í•˜ì§€ ì•ŠìŒ. ì—°ë„/ì¹´í…Œê³ ë¦¬ ë²”ìœ„ë¥¼ ë°”ê¿” í™•ì¸í•´ë´."]
st.markdown("\n".join(msgs))
